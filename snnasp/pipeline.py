'''This module provides classes for building tensorflow datasets which
    take data from a properly structured directory. Currently, the model
    defines a class for a dataset from tensorflow *.tfrecords files 
    generated by ARTRS.

    While these classes can be extended to include other formats, the 
    benefits of using the tensorflow dataset format include:
        - Speed benefits since input data is not converted to tensors during
        execution
        - Better memory management since tensorflow can manage when new entries
        from the dataset are loaded into main memory
'''
import tensorflow as tf
import numpy as np

import glob
from abc import ABC, abstractmethod

#Dictionary containing information used to parse tfRecords files
tfRecordsFeatures = {
        'ARTRS': {
            'Scene': tf.FixedLenFeature([], tf.string),
            'sampleRate': tf.FixedLenFeature([1], tf.int64),
            'numRecs': tf.FixedLenFeature([1], tf.int64),
            'micArrOrigin': tf.FixedLenFeature([3], tf.float32),
            'micSteer': tf.FixedLenFeature([3], tf.float32),

            'speaker1': tf.FixedLenFeature([], tf.string),
            'location1': tf.FixedLenFeature([3], tf.float32),
            'signal1': tf.FixedLenFeature([16000*60], tf.float32),

            'speaker2': tf.FixedLenFeature([], tf.string),
            'location2': tf.FixedLenFeature([3], tf.float32),
            'signal2': tf.FixedLenFeature([16000*60], tf.float32),
            
            'speaker3': tf.FixedLenFeature([], tf.string),
            'location3': tf.FixedLenFeature([3], tf.float32),
            'signal3': tf.FixedLenFeature([16000*60], tf.float32),

            'traceData': tf.FixedLenFeature([], tf.string),
        },
    }

class TfCorpus(ABC):
    '''Base class for a data pipeline from any corpus. Allows for
        forward compatibility.

        A corpus is expected to include a set of TfRecords which contain
        input audio data and expected output audio data with steering
        information optionally available. Data is expected to be generated
        by ARTRS, but any appropriate dataset should be allowed.
    '''
    parent = ""
    dataset = None
    features = None
    numEntries = 0
    @abstractmethod
    def __init__(self, directory, filePat):
        self.path = self.parent + directory
        self.fileList = [entry.replace("\\", "/") for entry in glob.glob(self.path+filePat)]
        self.numEntries = len(self.fileList)

    @abstractmethod
    def Prepare(self):
        raise NotImplementedError

    def __iter__(self):
        return iter(self.dataset)

    def Buffer(self, buffSize, copy=False):
        '''Buffers the dataset into batches each with length of buffSize samples.
            This should only be called once the dataset has been distilled into
            input-output pairs.
        '''
        if copy: #return pointer to a buffered dataset map; doesn't actually copy data
            return self.dataset.map(lambda *data: (self.BufferSingle(data[0], buffSize), self.BufferSingle(data[1], buffSize)))
        else:
            self.dataset = self.dataset.map(lambda *data: (self.BufferSingle(data[0], buffSize), self.BufferSingle(data[1], buffSize)))

    def BufferSingle(self, tensor, buffSize):
        '''Helper function that divides input tensor into sections of length
            buffSize and returns a tensor of shape (batchSize, buffSize, channels)'''
        if len(tensor.shape) > 1:
            channels = tensor.shape[1]
            if channels == 1:
                return tf.reshape(tensor, shape=(-1, buffSize))
            else:
                return tf.reshape(tensor, shape=(-1, buffSize, channels))
        else:
            return tf.reshape(tensor, shape=(-1, buffSize))

    def Parse(self):
        '''Parses self.dataset according to the dictionary in self.features
        '''
        self.dataset = self.dataset.map(self.ParseSingle)
        
    def ParseSingle(self, serialized):
        return tf.parse_single_example(serialized, self.features)

    def Map(self, func):
        self.dataset = self.dataset.map(func)

    def MapChannel(self, func, channels=[]):
        '''Apply a transformation to a specific channel of the overall
            dataset (e.g. transform just input but not output data).
            
            "channels" should have the same dimensions as the dataset
            and indicate true for each index corresponding to a channel
            to be transformed.
        '''
        self.dataset = self.dataset.map(lambda *dataset: [func(data) if channels[index] else data
                                                            for index, data in enumerate(dataset)] )

    def Scale(self, scale):
        self.dataset = self.dataset.map(lambda *dataset: [data*scale for data in dataset])

    def Shift(self, shift):
        self.dataset = self.dataset.map(lambda *dataset: [data + shift for data in dataset])

    def Split(self, portion):
        '''Splits the dataset into individual training and test sets with the
            training set approximately the (decimal) portion size specified.
        '''
        numTraining = round(portion*self.numEntries)
        return self.dataset.take(numTraining), self.dataset.skip(numTraining)

class Ready(TfCorpus):
    '''Class to wrap a prepared tf dataset object with the preparation
        methods defined in this module
    '''
    def __init__(self, dataset, numEntries = -1):
        self.path = None
        self.fileList = None
        self.numEntries = numEntries
        self.dataset = dataset

    def Prepare(self):
        pass



class ARTRS(TfCorpus):
    '''Pipeline class specifically for ARTRS generated files.
    '''
    parent = "./Dataset/"
    features = tfRecordsFeatures["ARTRS"] #dictionary for unpacking TfRecords files

    def __init__(self, directory, keys, filePat="/*.tfrecords"):
        super().__init__(directory, filePat)
        self.keys = keys
        self.Prepare()

    def Prepare(self):
        self.dataset = tf.data.TFRecordDataset(self.fileList)
        self.Parse()
        self.dataset = self.dataset.map(self.IsolateKeys)
        self.dataset = self.dataset.map(self.PrepareSingle)

    def PrepareSingle(self, *data):
        traceData = tf.parse_tensor(data[0], "float32")
        traceData.set_shape([960000, 8])
        return (traceData, *data[1:])

    def IsolateKeys(self, data):
        tensors = [data[key] for key in self.keys]
        return tensors


class LibriSpeech(ARTRS):
    '''Pipeline class specifically for ARTRS generated files from the LibriSpeech
        audio corpus.
    '''
    parent = "./Dataset/LibriSpeech/"
    keys = ["traceData", "signal1", "location1", "micArrOrigin"]
    def __init__(self, directory, filePat="/*.tfrecords"):
        super().__init__(directory, self.keys)
        self.dataset = self.dataset.map(self.Align)

    def Align(self, *data):
        #calculate euclidian distance
        distance = tf.squared_difference(data[2], data[3])
        distance = tf.reduce_sum(distance)
        distance = tf.sqrt(distance)

        #pad signal1 with zeros to simulate delay of source signal
        numSamples = data[1].shape[0].value
        delay = tf.cast(tf.round(distance/343*16000), "int32") #expected sample delay in seconds
        targetSignal = tf.pad(data[1], [[delay, 0]])[:numSamples]
        targetSignal.set_shape((960000,))

        return data[0], targetSignal

        

class PureTones(TfCorpus):
    '''Pipeline class for generating a pure tone dataset for frequency evaluation.
    '''
    def __init__(self, inChannels=8, outChannels=1, space=np.linspace,
                spParams=(20, 20*10**3, 60), sampRate=16000, duration=60):
        '''Creates a tensorflow dataset with given parameters

            space--the distribution of frequencies in the dataset (i.e. linear, logarithmic, etc)
            spParams--parameters for numpy function like linspace
        '''
        self.inChannels = inChannels
        self.outChannels = outChannels
        self.space =  space(*spParams)
        self.sampRate = sampRate
        self.duration = duration
        self.arrLen = sampRate*duration
        self.Prepare()

    def Generate(self):
        for frequency in self.space:
            timeScale = np.arange(self.arrLen)/self.sampRate
            inArr = np.zeros((self.arrLen, self.inChannels), dtype=np.float32)
            inArr[:,0] += np.sin(frequency/(2*np.pi) * timeScale)
            outArr = np.zeros((self.arrLen, self.outChannels), dtype=np.float32)
            outArr[:,0] += np.sin(frequency/(2*np.pi) * timeScale)
            yield inArr, outArr

    def Prepare(self):
        self.dataset = tf.data.Dataset.from_generator(self.Generate,
                                                    (tf.float32, tf.float32),
                                                    ((self.arrLen, self.inChannels), (self.arrLen, self.outChannels))
                                                    )

    

#---------------Development Code---------------#
if __name__ == "__main__":
    #Run as 'python -i pipeline.py' to examine these variables with interpreter
    pipeline = LibriSpeech("dev-clean-mix")
    firstEntry = iter(pipeline.dataset).next()
    traceData = firstEntry[0]
    raw = firstEntry[1]

    import matplotlib.pyplot as plt
    dummyPipeline = PureTones()
    timeScale = np.arange(16000*60)/16000
    dummyPipeline.Buffer(240)
    inExample, outExample = iter(dummyPipeline.dataset).next()
    
