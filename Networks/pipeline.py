'''This module provides classes for building tensorflow datasets which
    take data from a properly structured directory. Currently, the model
    defines a class for a dataset from tensorflow *.tfrecords files 
    generated by ARTRS.

    While these classes can be extended to include other formats, the 
    benefits of using the tensorflow dataset format include:
        - Speed benefits since input data is not converted to tensors during
        execution
        - Better memory management since tensorflow can manage when new entries
        from the dataset are loaded into main memory
'''
import tensorflow as tf
import numpy as np

import glob
from abc import ABC, abstractmethod

#Dictionary containing information used to parse tfRecords files
tfRecordsFeatures = {
        'ARTRS': {
            'Scene': tf.io.FixedLenFeature([], tf.string),
            'sampleRate': tf.io.FixedLenFeature([1], tf.int64),
            'numRecs': tf.io.FixedLenFeature([1], tf.int64),
            'micArrOrigin': tf.io.FixedLenFeature([3], tf.float32),
            'micSteer': tf.io.FixedLenFeature([3], tf.float32),

            'speaker1': tf.io.FixedLenFeature([], tf.string),
            'location1': tf.io.FixedLenFeature([3], tf.float32),
            'signal1': tf.io.FixedLenFeature([16000*60], tf.float32),

            'speaker2': tf.io.FixedLenFeature([], tf.string),
            'location2': tf.io.FixedLenFeature([3], tf.float32),
            'signal2': tf.io.FixedLenFeature([16000*60], tf.float32),
            
            'speaker3': tf.io.FixedLenFeature([], tf.string),
            'location3': tf.io.FixedLenFeature([3], tf.float32),
            'signal3': tf.io.FixedLenFeature([16000*60], tf.float32),

            'traceData': tf.io.FixedLenFeature([], tf.string),
        },
    }

class TfCorpus(ABC):
    '''Base class for a data pipeline from any corpus. Allows for
        forward compatibility.

        A corpus is expected to include a set of TfRecords which contain
        input audio data and expected output audio data with steering
        information optionally available. Data is expected to be generated
        by ARTRS, but any appropriate dataset should be allowed.
    '''
    parent = ""
    dataset = None
    features = None
    numEntries = 0
    @abstractmethod
    def __init__(self, directory, filePat):
        self.path = self.parent + directory
        self.fileList = [entry.replace("\\", "/") for entry in glob.glob(self.path+filePat)]
        self.numEntries = len(self.fileList)

    @abstractmethod
    def Prepare(self):
        raise NotImplementedError

    def Buffer(self, buffSize):
        self.dataset = self.dataset.map(lambda *data: (self.BufferSingle(data[0], buffSize), self.BufferSingle(data[1], buffSize)))

    def BufferSingle(self, tensor, buffSize):
        '''Divides input tensor into sections of length buffSize and
            returns a tensor of shape (batchSize, channels, buffSize)'''
        if len(tensor.shape) > 1:
            channels = tensor.shape[1]
            if channels == 1:
                return tf.reshape(tensor, shape=(-1, buffSize))
            else:
                return tf.transpose(tf.reshape(tensor, shape=(-1, buffSize, channels)), perm=[0, 2, 1])
        else:
            return tf.reshape(tensor, shape=(-1, buffSize))

    def Parse(self):
        '''Parses self.dataset according to the dictionary in self.features
        '''
        self.dataset = self.dataset.map(self.ParseSingle)
        
    def ParseSingle(self, serialized):
        return tf.io.parse_single_example(serialized, self.features)



class ARTRS(TfCorpus):
    '''Pipeline class specifically for ARTRS generated files.
    '''
    parent = "../Dataset/"
    features = tfRecordsFeatures["ARTRS"] #dictionary for unpacking TfRecords files

    def __init__(self, directory, keys, filePat="/*.tfrecords"):
        super().__init__(directory, filePat)
        self.keys = keys
        self.Prepare()

    def Prepare(self):
        self.dataset = tf.data.TFRecordDataset(self.fileList)
        self.Parse()
        self.dataset = self.dataset.map(self.IsolateKeys)
        self.dataset = self.dataset.map(self.PrepareSingle)

    def PrepareSingle(self, *data):
        return (tf.io.parse_tensor(data[0], "float32"), *data[1:])

    def IsolateKeys(self, data):
        tensors = [data[key] for key in self.keys]
        return tensors


class LibriSpeech(ARTRS):
    '''Pipeline class specifically for ARTRS generated files from the LibriSpeech
        audio corpus.
    '''
    parent = "../Dataset/LibriSpeech/"
    keys = ["traceData", "signal1", "location1", "micArrOrigin"]
    def __init__(self, directory, filePat="/*.tfrecords"):
        super().__init__(directory, self.keys)
        self.dataset = self.dataset.map(self.Align)

    def Align(self, *data):
        #calculate euclidian distance
        distance = tf.math.squared_difference(data[2], data[3])
        distance = tf.math.reduce_sum(distance)
        distance = tf.sqrt(distance)

        #pad signal1 with zeros to simulate delay of source signal
        numSamples = len(data[1])
        delay = tf.cast(tf.round(distance/343*16000), "int32") #expected sample delay in seconds
        targetSignal = tf.pad(data[1], [[delay, 0]])[:numSamples]

        return data[0], targetSignal

        

class PureTones(TfCorpus):
    '''Pipeline class for generating a pure tone dataset for frequency evaluation.
    '''
    def __init__(self, inChannels=8, outChannels=1, space=np.linspace,
                spParams=(20, 20*10**3, 60), sampRate=16000, duration=60):
        '''Creates a tensorflow dataset with given parameters

            space--the distribution of frequencies in the dataset (i.e. linear, logarithmic, etc)
            spParams--parameters for numpy function like linspace
        '''
        self.inChannels = inChannels
        self.outChannels = outChannels
        self.space =  space(*spParams)
        self.sampRate = sampRate
        self.duration = duration
        self.arrLen = sampRate*duration
        self.Prepare()

    def Generate(self):
        for frequency in self.space:
            timeScale = np.arange(self.arrLen)/self.sampRate
            inArr = np.zeros((self.arrLen, self.inChannels), dtype=np.float32)
            inArr[:,0] += np.sin(frequency/(2*np.pi) * timeScale)
            outArr = np.zeros((self.arrLen, self.outChannels), dtype=np.float32)
            outArr[:,0] += np.sin(frequency/(2*np.pi) * timeScale)
            yield inArr, outArr

    def Prepare(self):
        self.dataset = tf.data.Dataset.from_generator(self.Generate,
                                                    (tf.float32, tf.float32),
                                                    ((self.arrLen, self.inChannels), (self.arrLen, self.outChannels))
                                                    )

    

#---------------Development Code---------------#
if __name__ == "__main__":
    #Run as 'python -i pipeline.py' to examine these variables with interpreter
    pipeline = LibriSpeech("dev-clean-mix")
    firstEntry = iter(pipeline.dataset).next()
    traceData = firstEntry[0]
    raw = firstEntry[1]

    import matplotlib.pyplot as plt
    dummyPipeline = PureTones()
    timeScale = np.arange(16000*60)/16000
    dummyPipeline.Buffer(240)
    inExample, outExample = iter(dummyPipeline.dataset).next()
    
